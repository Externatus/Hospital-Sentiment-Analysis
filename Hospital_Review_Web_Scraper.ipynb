{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hospital-Review-Web-Scraper.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnl4DGwj5t41",
        "colab_type": "code",
        "outputId": "c1bc7d58-a1b7-4c46-a582-cc526cdf89ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install beautifulsoup4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT5jrznu52ew",
        "colab_type": "code",
        "outputId": "bdb2008d-ae87-4625-9ed6-fcf8b153c3a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install lxml"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (4.2.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IAoXeueAH41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from requests import get\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIn6i87M555i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getHTMLContent(url): \n",
        "  try:\n",
        "    response = get(url)\n",
        "    html = BeautifulSoup(response.text, 'html.parser')\n",
        "  except Exception as e:\n",
        "    html = None\n",
        "  return html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-p5ZP2n86NR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hospitals = {\n",
        "  'rajavithi': 'https://www.honestdocs.co/hospitals/rajavithi-hospital',\n",
        "  'bumrungrad': 'https://www.honestdocs.co/hospitals/bumrungrad-hospital',\n",
        "  'lerdsin': 'https://www.honestdocs.co/hospitals/lerdsin-hospital'\n",
        "}\n",
        "for key, url in hospitals.items():\n",
        "  ratings = []\n",
        "  reviews = []\n",
        "  page = 1\n",
        "  while True:\n",
        "    time.sleep(1)\n",
        "    full_url = url+'?page='+str(page)\n",
        "    html = getHTMLContent(full_url)\n",
        "    if html is None:\n",
        "      break\n",
        "    comments = html.find_all('div', class_='comments__container')\n",
        "    if not comments :\n",
        "      break\n",
        "    for comment in comments:\n",
        "      rating = comment.find(\"span\", class_=\"star-rating\")[\"data-score\"]\n",
        "      if(int(rating) == 3):\n",
        "        continue\n",
        "      elif (int(rating) <= 2):\n",
        "        ratings.append(\"0\")\n",
        "      else:\n",
        "        ratings.append(\"1\")\n",
        "      review = comment.find(\"div\", class_=\"comments__content\").p.text\n",
        "      reviews.append(review)\n",
        "    page += 1\n",
        "  df = pd.DataFrame({\"reviews\": reviews,\n",
        "                   \"ratings\": ratings})\n",
        "  df.to_csv(key+\".csv\", index=False)\n",
        "  time.sleep(5)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}