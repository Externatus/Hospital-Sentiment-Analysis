{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SBuD-kTKuIzG"
   },
   "outputs": [],
   "source": [
    "#Utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#NLP\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import  mark_negation\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCB7lRYyuWWw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\baspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\baspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\baspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\baspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\baspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\baspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download resource\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stopwords(reviews_en):\n",
    "    tokenize_words_list = []\n",
    "    for row in reviews_en:\n",
    "        words = nltk.tokenize.word_tokenize(row) \n",
    "        tokenize_words = [word.lower() for word in words if word not in nltk.corpus.stopwords.words(\"english\")]\n",
    "        tokenize_words_list.append(tokenize_words)\n",
    "    return tokenize_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# corpus_words = set(nltk.corpus.words.words())\n",
    "\n",
    "def apply_lemmatize(word_list):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentence_list = []\n",
    "    for words in word_list:\n",
    "        lemmatized_sentence = []\n",
    "        for word, tag in pos_tag(words):\n",
    "            if tag.startswith('NN'):\n",
    "                pos = 'n'\n",
    "            elif tag.startswith('VB'):\n",
    "                pos = 'v'\n",
    "            else:\n",
    "                pos = 'a'\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, pos))\n",
    "            list_to_str = ' '.join([str(elem) for elem in lemmatized_sentence]) \n",
    "#             str_in_corpus = ' '.join(w for w in nltk.wordpunct_tokenize(list_to_str) if w in corpus_words or not w.isalpha())\n",
    "        lemmatized_sentence_list.append(list_to_str)\n",
    "    return lemmatized_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLgC15BJulgu"
   },
   "outputs": [],
   "source": [
    "hospital_list = [\"bumrungrad\",  \"lerdsin\", \"rajavithi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76aWPBXfupME"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"lerdsin-translated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>จำไม่ได้ว่าปีไหน น่าจะ ช่วงปลายปี 57 หรือ 58 ต...</td>\n",
       "      <td>1</td>\n",
       "      <td>I can't remember which year it was at the end ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>เคยใช้บริการตอนขาหัก โดยใช้สิทธิ์ประกันสังคม ไ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I had a broken leg The right to social securit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>รอคิวตรวจนานมากค่ะ มาตั้งแต่ 6 โมงเช้า กว่าจะไ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Make me wait so long since 6 am to 3 pm, they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>มาครั้งแรก ประทับใจมากคับ บริการเหมือน รพ เอกช...</td>\n",
       "      <td>1</td>\n",
       "      <td>The first impression is very good services lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>บริการดีครับ แต่คนเยอะมากๆเลย ที่ใช้บริการคือม...</td>\n",
       "      <td>1</td>\n",
       "      <td>Good service, but a lot of people yet. The ser...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ratings  \\\n",
       "0  จำไม่ได้ว่าปีไหน น่าจะ ช่วงปลายปี 57 หรือ 58 ต...        1   \n",
       "1  เคยใช้บริการตอนขาหัก โดยใช้สิทธิ์ประกันสังคม ไ...        1   \n",
       "2  รอคิวตรวจนานมากค่ะ มาตั้งแต่ 6 โมงเช้า กว่าจะไ...        1   \n",
       "3  มาครั้งแรก ประทับใจมากคับ บริการเหมือน รพ เอกช...        1   \n",
       "4  บริการดีครับ แต่คนเยอะมากๆเลย ที่ใช้บริการคือม...        1   \n",
       "\n",
       "                                          reviews_en  \n",
       "0  I can't remember which year it was at the end ...  \n",
       "1  I had a broken leg The right to social securit...  \n",
       "2  Make me wait so long since 6 am to 3 pm, they ...  \n",
       "3  The first impression is very good services lik...  \n",
       "4  Good service, but a lot of people yet. The ser...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews_en</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>จำไม่ได้ว่าปีไหน น่าจะ ช่วงปลายปี 57 หรือ 58 ต...</td>\n",
       "      <td>1</td>\n",
       "      <td>I can't remember which year it was at the end ...</td>\n",
       "      <td>[i, ca, n't, remember, year, end, year, 57, 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>เคยใช้บริการตอนขาหัก โดยใช้สิทธิ์ประกันสังคม ไ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I had a broken leg The right to social securit...</td>\n",
       "      <td>[i, broken, leg, the, right, social, security,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>รอคิวตรวจนานมากค่ะ มาตั้งแต่ 6 โมงเช้า กว่าจะไ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Make me wait so long since 6 am to 3 pm, they ...</td>\n",
       "      <td>[make, wait, long, since, 6, 3, pm, ,, checked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>มาครั้งแรก ประทับใจมากคับ บริการเหมือน รพ เอกช...</td>\n",
       "      <td>1</td>\n",
       "      <td>The first impression is very good services lik...</td>\n",
       "      <td>[the, first, impression, good, services, like,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>บริการดีครับ แต่คนเยอะมากๆเลย ที่ใช้บริการคือม...</td>\n",
       "      <td>1</td>\n",
       "      <td>Good service, but a lot of people yet. The ser...</td>\n",
       "      <td>[good, service, ,, lot, people, yet, ., the, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ratings  \\\n",
       "0  จำไม่ได้ว่าปีไหน น่าจะ ช่วงปลายปี 57 หรือ 58 ต...        1   \n",
       "1  เคยใช้บริการตอนขาหัก โดยใช้สิทธิ์ประกันสังคม ไ...        1   \n",
       "2  รอคิวตรวจนานมากค่ะ มาตั้งแต่ 6 โมงเช้า กว่าจะไ...        1   \n",
       "3  มาครั้งแรก ประทับใจมากคับ บริการเหมือน รพ เอกช...        1   \n",
       "4  บริการดีครับ แต่คนเยอะมากๆเลย ที่ใช้บริการคือม...        1   \n",
       "\n",
       "                                          reviews_en  \\\n",
       "0  I can't remember which year it was at the end ...   \n",
       "1  I had a broken leg The right to social securit...   \n",
       "2  Make me wait so long since 6 am to 3 pm, they ...   \n",
       "3  The first impression is very good services lik...   \n",
       "4  Good service, but a lot of people yet. The ser...   \n",
       "\n",
       "                                               words  \n",
       "0  [i, ca, n't, remember, year, end, year, 57, 58...  \n",
       "1  [i, broken, leg, the, right, social, security,...  \n",
       "2  [make, wait, long, since, 6, 3, pm, ,, checked...  \n",
       "3  [the, first, impression, good, services, like,...  \n",
       "4  [good, service, ,, lot, people, yet, ., the, s...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"words\"] = apply_stopwords(df[\"reviews_en\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews_en</th>\n",
       "      <th>words</th>\n",
       "      <th>lemma_word_of_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>จำไม่ได้ว่าปีไหน น่าจะ ช่วงปลายปี 57 หรือ 58 ต...</td>\n",
       "      <td>1</td>\n",
       "      <td>I can't remember which year it was at the end ...</td>\n",
       "      <td>[i, ca, n't, remember, year, end, year, 57, 58...</td>\n",
       "      <td>i ca n't remember year end year 57 58 . at tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>เคยใช้บริการตอนขาหัก โดยใช้สิทธิ์ประกันสังคม ไ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I had a broken leg The right to social securit...</td>\n",
       "      <td>[i, broken, leg, the, right, social, security,...</td>\n",
       "      <td>i break leg the right social security i pay ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>รอคิวตรวจนานมากค่ะ มาตั้งแต่ 6 โมงเช้า กว่าจะไ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Make me wait so long since 6 am to 3 pm, they ...</td>\n",
       "      <td>[make, wait, long, since, 6, 3, pm, ,, checked...</td>\n",
       "      <td>make wait long since 6 3 pm , check hospital c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>มาครั้งแรก ประทับใจมากคับ บริการเหมือน รพ เอกช...</td>\n",
       "      <td>1</td>\n",
       "      <td>The first impression is very good services lik...</td>\n",
       "      <td>[the, first, impression, good, services, like,...</td>\n",
       "      <td>the first impression good service like hospita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>บริการดีครับ แต่คนเยอะมากๆเลย ที่ใช้บริการคือม...</td>\n",
       "      <td>1</td>\n",
       "      <td>Good service, but a lot of people yet. The ser...</td>\n",
       "      <td>[good, service, ,, lot, people, yet, ., the, s...</td>\n",
       "      <td>good service , lot people yet . the service re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  ratings  \\\n",
       "0  จำไม่ได้ว่าปีไหน น่าจะ ช่วงปลายปี 57 หรือ 58 ต...        1   \n",
       "1  เคยใช้บริการตอนขาหัก โดยใช้สิทธิ์ประกันสังคม ไ...        1   \n",
       "2  รอคิวตรวจนานมากค่ะ มาตั้งแต่ 6 โมงเช้า กว่าจะไ...        1   \n",
       "3  มาครั้งแรก ประทับใจมากคับ บริการเหมือน รพ เอกช...        1   \n",
       "4  บริการดีครับ แต่คนเยอะมากๆเลย ที่ใช้บริการคือม...        1   \n",
       "\n",
       "                                          reviews_en  \\\n",
       "0  I can't remember which year it was at the end ...   \n",
       "1  I had a broken leg The right to social securit...   \n",
       "2  Make me wait so long since 6 am to 3 pm, they ...   \n",
       "3  The first impression is very good services lik...   \n",
       "4  Good service, but a lot of people yet. The ser...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [i, ca, n't, remember, year, end, year, 57, 58...   \n",
       "1  [i, broken, leg, the, right, social, security,...   \n",
       "2  [make, wait, long, since, 6, 3, pm, ,, checked...   \n",
       "3  [the, first, impression, good, services, like,...   \n",
       "4  [good, service, ,, lot, people, yet, ., the, s...   \n",
       "\n",
       "                              lemma_word_of_sentence  \n",
       "0  i ca n't remember year end year 57 58 . at tim...  \n",
       "1  i break leg the right social security i pay ca...  \n",
       "2  make wait long since 6 3 pm , check hospital c...  \n",
       "3  the first impression good service like hospita...  \n",
       "4  good service , lot people yet . the service re...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemma_word_of_sentence\"] = apply_lemmatize(df[\"words\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "vectorizer = TfidfVectorizer()  \n",
    "\n",
    "vectors = tfidfconverter.fit_transform(df[\"lemma_word_of_sentence\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 386)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039641</td>\n",
       "      <td>0.04093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138848</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153920</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.611028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.337049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4         5    6    7    8         9    ...  376  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.052727  0.0  0.0  0.0  0.000000  ...  0.0   \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  ...  0.0   \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.212526  ...  0.0   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  ...  0.0   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  ...  0.0   \n",
       "..   ...  ...  ...  ...  ...       ...  ...  ...  ...       ...  ...  ...   \n",
       "394  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.611028  ...  0.0   \n",
       "395  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  ...  0.0   \n",
       "396  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.337049  ...  0.0   \n",
       "397  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  ...  0.0   \n",
       "398  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  ...  0.0   \n",
       "\n",
       "     377       378      379  380       381  382       383       384  385  \n",
       "0    0.0  0.039641  0.04093  0.0  0.095192  0.0  0.000000  0.000000  0.0  \n",
       "1    0.0  0.000000  0.00000  0.0  0.000000  0.0  0.000000  0.138848  0.0  \n",
       "2    0.0  0.000000  0.00000  0.0  0.000000  0.0  0.000000  0.153920  0.0  \n",
       "3    0.0  0.000000  0.00000  0.0  0.000000  0.0  0.199838  0.000000  0.0  \n",
       "4    0.0  0.000000  0.00000  0.0  0.000000  0.0  0.191613  0.000000  0.0  \n",
       "..   ...       ...      ...  ...       ...  ...       ...       ...  ...  \n",
       "394  0.0  0.000000  0.00000  0.0  0.000000  0.0  0.000000  0.000000  0.0  \n",
       "395  0.0  0.000000  0.00000  0.0  0.000000  0.0  0.000000  0.000000  0.0  \n",
       "396  0.0  0.000000  0.00000  0.0  0.000000  0.0  0.000000  0.000000  0.0  \n",
       "397  0.0  0.000000  0.00000  0.0  0.000000  0.0  0.000000  0.000000  0.0  \n",
       "398  0.0  0.000000  0.00000  0.0  0.000000  0.0  0.000000  0.000000  0.0  \n",
       "\n",
       "[399 rows x 386 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf_df = pd.DataFrame(vectors, column=vectorizer.get_feature_names())\n",
    "tfidf_df = pd.DataFrame(vectors)\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Hospital_Review_Sentiment_Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
